// 2022.07.26

// Jisoo Lee (Brown)

# 캐시 메모리 (Cache Memory)

<details>
  <summary> 캐시, 우리가 흔히 들었던 쿠키랑 다른가? 🍪💸 </summary>
  <div markdown="1">
    🍪 쿠키에 대해서 간단하게 알고가보자 (쿠키가 사용되는 예시) <br>
    👉 일단 쿠키는 사용자가 검색을 한다거나 컴퓨터에서 드라이브, 폴더를 이동하는 등의 작업 내용의 일부를 저장한다. 사용자가 다음에 동일한 작업을 할ㄷ 때 저장된 것을 불러와서 처음 작업을 할 때보다 훨씬 빠른 속도로 응답할 수 있다. <br>
    👉 더불어 쿠키는, 어떤 키워드를 웹상에 입력할 때, 첫자만 입력해서 전체 단어가 나타나게 하는 것도 쿠키에 저장된 데이터를 불러오는 것이다. 비밀번호 같은것들도 마찬가지다. <br>
    <br>
    💸 캐시는 사용기록을 저장하는 것은 동일하지만, 하드디스크보다 (로컬) 훨씬 빠른 고속 메모리에 데이터를 저장한다. 메모리는 하드디스크보다 훨씬 빠르고 사용자가 호출한 정보를 자동으로 복사해서 복사본은 임시저장소에 저장한다. <br>
    <br>
    🚨가장 다른점은, 쿠키는 내 컴퓨터 저장공간에 저장되지만, 캐시는 도메인의 서버 저장공간에도 저장된다. 
    <br> 
    [쿠키와 캐시를 비교하는 참고자료](https://omnislog.com/1228) </br>
  </div>
</details>
## 🟣 캐시 (Cache) 란?

자주 사용하는 데이터나 값을 미리 복사해 놓는 임시 장소를 말한다.

## 🟣 캐시 메모리(Cache Memory)란?

어떤 프로그램을 동작시키기 위해서는 메모리에 적재가 되고, CPU를 할당받아야 동작이 된다. 이때 CPU와 RAM(메모리)사이에서 활발하게 데이터를 주고받게 되는데, CPU에 비해서 속도가 느린 메모리에 의해서 프로그램이 제대로 성능을 내지 못한다.

이렇게 속도가 빠른 장치(CPU)와, 느린 장치(RAM)에서 속도 차이에 의해 생기는 병목현상을 줄이기 위한 메모리가 **캐시 메모리**이다. 

```
속도가 빠른것과 느린것의 예시는?

CPU와 메모리 사이의 속도 차이 (병목현상)을 완화
웹 브라우저 예시) 하드디스크와 웹페이지 사이의 병목 현상을 완화
```

![img](https://mangchhe.github.io/assets/postImages/CacheMemory/computerMemory.png)



CPU가 주기억장치에서 저장된 데이터를 읽어올 때, 자주사용하는 데이터는 캐시에 저장한 뒤 다음에 이용될 때 주기억장치가 아닌 캐시 메모리에서 먼저 가져오면서 속도를 향상시킨다. (하지만 용량이 작고, 비용이 비싸다는 단점이 있다.)

CPU에는 이러한 **캐시메모리가 2~3개 정도 사용**된다. (L1, L2, L3 캐시메모리) 속도와 크기에 따라 분류한 것이고, 일반적으로 L1부터 사용된다. (CPU에서 가장 빠르게 접근하고, 여기서 데이터를 찾지 못하면 L2로 가는 방식이다.)

```
<캐시의 종류>

L1 cache: CPU 내부에 존재, 프로세서와 가장 가까이 존재한다. 속도를 위해서 두가지로 나뉜다.
	- Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시
	- Data Cache (D$): TEXT영역을 제외한 모든 데이터를 다루는 캐시
L2 cache: CPU와 RAM 사이에 존재, 용량이 큰 캐시이다. 
L3: 보통 메인보드에 존재, 멀티 코어 시스템에서 여러 코어가 공유하는 캐시이다.

보통 L1 -> L2 -> L3 -> DRAM 순서로 데이터를 탐색한다.
```

> 💁🏻 알고가면 좋을 것
>
> - 듀얼 코어 프로세서의 캐시메모리
>   - 각 코어마다 독립된 L1 캐시 메모리를 가지고, 두 코어가 공유하는 L2 캐시 메모리가 내장되어있다. 
>   - 만약 L1 캐시가 128kb이면, 64/64로 나누어 64kb에 명령어를 처리하기 직전의 명령어를 임시저장하고, 나머지 64kb에는 실행 후 명령어를 저장한다. (명령어 세트로 구성한다. I-cache, D-cache) 
>   - **(질문)** 이게.. I$, D$ 와 관련이 있는걸까...?



### 🟣 캐시(Cache)의 특징

- 캐시의 데이터는 일반적으로 RAM과 같이 빠르게 엑세스할 수 있는 '하드웨어'에 저장되고, 소프트웨어 구성 요소와 함께 사용될 수도 있다.
- 캐시는 기본 스토리지 계층 (SSD, HDD)에 엑세스하여 데이터를 가져오는 더 느린 작업의 요구를 줄이고, 데이터 검색의 성능을 높인다.
- 속도를 위해 용량을 절충하는 캐시는 일반적으로 데이터의 하위 집합을 일시적으로 저장한다. 완전히 영구적인 데이터가 있는 DB와는 다르다.
- 투명성 : 프로그래머는 캐시를 조작할 수 있는 명령어가 없다.



### 🟣 캐시(Cache)의 장점

임시장소라고 이해하면 편하다. 첫 작업 이후에 동일한 데이터에 대한 요청이 있을 경우, 데이터의 기본 저장 공간에 접근해서 탐색할 때보다, 캐시에 접근해서 빠르게 요청할 수 있다는 장점이 있다. 더불어 캐시를 사용하면 이전에 사용했던 데이터를 효율적으로 재사용할 수 있다.

- 애플리케이션 성능개선
- DB 비용 절감
- 백엔드 부하 감소
- 예측 가능한 성능
- DB 핫스팟 제거
- 읽기 처리량 증가



### 🟣 캐시의 Hit 과 Miss

- **Hit** : 요청한 데이터가 캐시에 존재하는 경우 
- **Miss** : 요청한 데이터가 존재하지 않는 경우

CPU는 메모리에 접근하기 전에 캐시 메모리를 먼저 들러서 찾고자하는 데이터가 있는지 확인한다. 캐시 메모리에서 데이터를 찾는 프로세스는 다음과 같다.

![ComputerMemory](https://mangchhe.github.io/assets/postImages/CacheMemory/dataFlowChart.png)

- Cache Hit 할 경우: 캐시 메모리에서 데이터를 CPU 레지스터에 복사한다.
- Cache Miss & 메모리에서 찾았을 경우:  메모리의 데이터를 캐시 메모리에 복사하고, 캐시 메모리에 복제된 내용을 CPU 레지스터에 복사한다.
- Cache Miss & 메모리에서 찾지 못했을 경우: 보조기억장치에서 메모리에 적재하고, 적재된 내용을 캐시 메모리에 복사한다. 그리고 캐시 메모리의 데이터를 CPU 레지스터에 복사한다.

> 🤔 레지스터가 뭔가요? 
>
> - CPU에 존재하는 다목적 저장공간이라고 이해하자!
> - 레지스터는 메모리 계층의 최상위에 위치하며, 가장 빠른 속도로 접근이 가능한 메모리
> - 데이터와 명령어를 저장하는 역할을 하고, 일반적으로 현재 계산에 대한 값을 저장하는데 사용
>
> 💁🏻 그래서 캐시랑 다른점은?
>
> - 캐시: CPU와 별도로 있는 공간. 메인 메모리와 CPU 간의 속도 차이를 극복하기 위한 것
> - 레지스터: CPU 안에서 연산을 처리하기 위해서 데이터를 저장한느 공간



### 🟣 캐시의 성능

캐시 메모리 성능은 **적중률**에 의해 결정된다. **적중률**이란, 요청한 데이터를 캐시 메모리에서 찾을 확률을 '캐시 적중률 cache hit ratio'라고 한다.

```
적중률 = 캐시 메모리의 적중(Hit) 횟수 / 전체 메모리의 참조 횟수 
miss ratio = 1 - 적중률
```

 그리고 '평균접근시간'으로도 캐시의 성능을 파악할 수 있다.

```
Hit latency + (Miss ratio * Miss latency)

- Hit latency: Hit가 발생해 캐싱된 데이터를 가져오는 시간
- Miss latency: Miss가 발생해 상위 캐시나 메인메모리에서 데이터를 가져오는 시간
```

캐시를 잘 활용해서 miss ratio를 줄이면, 비용을 많이 줄일 수 있다.

따라서 CPU가 어떤 데이터를 원할지 어느정도 예측하여 캐시에 쓸모 있는 정보가 들어있도록 해야한다. 이 때 캐시의 효율을 극대화 시키기 위해서 어느 데이터를 원할지 판단에 사용되는 것이 바로 **'지역성의 원리**'이다.



### 🟣 캐시 메모리의 지역성의 원리 (Locality)

- **시간지역성**: for, while 과 같은 반복문에서 사용하는 조건 변수처럼, 한 번 참조된 데이터는 잠시 후 또 참조될 가능성이 크다는 성질 (사용됐던 데이터는 가까운 시일내에 다시 사용된다.)
- **공간지역성**: A[0], A[1]과 같은 연속 접근시, 참조된 데이터의 인접한 데이터가 잠시후 또 사용될 가능성이 높다.
- **순차적지역성**: 분기가 발생하지 않는 이상, 순차적으로 실행될 가능성이 더 크다.

캐시메모리는 이러한 **지역성의 원리**을 최대한 활용하기 위해 해당 데이터 뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다.



### 🟣 캐시의 구조

캐시는 반응속도가 빠른 SRAM(Static Random Access Memory)로 주소가 키로 주어지면 해당 공간에 즉시 접근할 수 있다. 이러한 특성은 DRAM도 마찬가지지만, 하드웨어 설계상 DRAM은 SRAM보다 느리다.

주소가 키로 주어졌을때, 그 공간에 접근할 수 있다는 것은 캐시가 하드웨어로 구현한 해시테이블과 같다는 의미이다. 캐시가 빠른 이유는 자주 사용하는 데이터만 담아두기 때문이기도 하지만, 해시 테이블의 시간복잡도가 O(1)정도로 빠르기 때문이기도 하다.

캐시는 블록으로 구성되어있다. 각각의 블록은 데이터를 담고 있으며, 블록 개수와 블록의 크기가 캐시의 크기를 결정한다.



## 🟣 캐시에 필요한 전략과 설계 논점

이 개념을 알기 위해서는 태그 메모리에 대한 개념을 알아야한다. 먼저 살펴보자.

### 🟣 Tag memory (태그 메모리)

위에서 캐시는 블록으로 구성되어있다고 했다. 캐시는 고속메모리인 만큼, 메인 메모리보다 매우 작기때문에 블록으으로 구성되어 있다고 생각하면 편할 것이다.

 각 캐시 엔트리에는 메모리 내 여러 주소값 블록들이 적재되어있다. 태그 메모리는 캐시가 어떤 데이터를 포함하는지를 관리하기 위해서 사용한다.  **블록**은, 워드의 집합으로 데이터 메모리 내의 기본 단위라고 생각하자. (캐시와 메모리에의 데이터 전송 기본 단위이기도 하다)

![img](https://blog.kakaocdn.net/dn/Sw2tu/btqQBHwsYsg/ck77I4rbiXRDt6gHFYzXdk/img.png)

태그 메모리의 각 엔트리는 캐시의 데이터메모리의 블록들과 대응된다.  (그림에 쌍을 이루고 있음)

태그 메모리는 세 가지 정보를 포함한다.

- 태그 (tag) : CPU가 요청한 블록을 탐색하는데 사용하는 주소 정보의 일부
- 유효비트 (valid bit) : 캐시 블록이 유효한 데이터인지 아닌지를 표시
  - 컴퓨터가 부팅될 때, 모든 유효 비트를 무효로 초기화한다.
- 갱신비트 (dirty bit) : 메모리에서 캐시로 블록을 가져온 후, CPU가 블록을 수정했는지 표시

또한, CPU 주소와 태그를 비교할 수 있는 '비교기'도 갖고 있다.



### 🟣 캐시를 사용하는 데에는 다양한 방식이 있다. 하나씩 알아보자.

### 🟣 블록사상(mapping)방식

블록을 메모리에서 가져와서 캐시에 어디다가 어떻게 가져다 놓을지 정하는 것이다. 블록 mapping(사상)이 필요한 이유는 캐시가 메모리보다 용량이 작기 때문에 다수의 메모리 블록이 동일한 캐시 블록에 mapping 된다.

```
- 사상의 정의 
-> mapping
-> 캐시메모리와 주기억장치 사이에서 정보를 옮기는 것 
```



블록사상방식에도 3가지 방식이 있다.

- 직접사상 (direct mapping) : 메모리 블록을 정해진 하나의 캐시 블록에만 사상할 수 있다.
- 완전연관사상 (fully-associative mapping) : 메모리 블록을 어떤 캐시 블록에도 사상
- 직합연관사상 (set-associative mapping) : 직접 사상과 연관사상을 절충하여 메모리 블록을 정해진 블록 집합 내 어디든 사상



#### 🟣 직접 사상 방식 (direct mapping)

메인 메모리와 캐시를 똑같은 크기로 나누고 순서대로 매핑하는 것을 의미한다. 블록은 업로드 될 수 있는 라인이 지정되어 있다. 즉, 메모리의 블록들은 캐시에 들어올 때 자리가 이미 정해져 있다.

<img src="/Users/jisoo.pos/Library/Application Support/typora-user-images/image-20220727221105881.png" alt="image-20220727221105881" style="zoom:25%;" />

- 블럭의 크기는, 캐시라인의 크기와 같다. 
- 워드는 하나의 번지에서 저장되는 데이터의 단위를 의미한다.
- 예를들어, 사진처럼 하나의 블럭이 4라인이면, 캐시 한라인도 4워드이다.
- 라인은 가로로 이루어진 하나의 라인이다. 라인은 캐시메모리 각 슬롯에 저장되는 데이터의 길이이다. (가로)

<img src="/Users/jisoo.pos/Library/Application Support/typora-user-images/image-20220727220810086.png" alt="image-20220727220810086" style="zoom:25%;" />

이렇게 색상으로 보여지다시피, 직접사상방식은 자리가 정해져있다고 생각하면 편하다. 순서대로 블럭하나, 캐시하나를 매치했기 때문에 direct mapping이라고 한다.

여기서 0, 1, 2, 3 은 블록 순번이다. 0블럭에는 0,1,2,3 순번의 4개의 워드가 들어가 있을거고, 1블럭에는 4, 5, 6, 7워드가 들어가 있을 것이다.

<img src="/Users/jisoo.pos/Library/Application Support/typora-user-images/image-20220727220825625.png" alt="image-20220727220825625" style="zoom:25%;" />

맨앞에 남은 2bit 가 tag라고 해서 태그 번호를 나타낸다. 같은 라인을 공유하는 블록들은 서로 다른 태그를 갖는다. 즉, 맨 처음 0 빨강 블록이 0태그이면, 4 빨강 태그는 1태그이다.

#### 🟣 완전 연관사상 (fully-associative mapping)

메모리 블록을 어떤 캐시 블록에도 사상 가능한 방식이다. 즉, 캐시에 빈 공간이 있으면 그 곳에 사상시킨다.

직접사상보다 적중률이 높다는 장점을 갖는다. 단, CPU가 요청한 태그를 모든 캐시 태그와 병렬로 연결해야하기 때문에 8개의 비교기가 필요하고, 태그의 길이가 길다.

#### 🟣 집합연관사상 (set-associative mapping)

집합연관사상 방식은 직접사상방식과 완전연관사상방식을 합친 방식이다. 정해진 장소 내, 어느 블록에나 위치시킬 수 있다. 즉, 캐시를 일정 개수 집합으로 나누어 놓고 그 집합에서는 비어있는 한 어느곳에서 위치 가능하다.

<img src="/Users/jisoo.pos/Library/Application Support/typora-user-images/image-20220727223134919.png" alt="image-20220727223134919" style="zoom:50%;" />

### 🟣 블록교체 와 블록갱신

나중에 더 추가할 내용에 들어있겠지만 사상방식 과정을 보면, 중간중간에 블록 교체와 블록 갱신 방식에 따라 진행된다. (꼭 알아야하는 개념 중 하나..)

### 🟣 블록교체 방식

캐시 공간이 없어서 캐시 블록을 비워야할 때 어떤 캐시블록을 비울건지 결정하는 방식이다. (아직 잘 무슨말인지 모르겠다 ㅠㅠ) 블록을 교체하는 전략에는 여러가지 방법이 있다.

- Belady의 MIN 알고리즘
  - 이상적인 블록 교체 방식으로 가장 오랫동안 참조되지 않을 블록을 교체
  - 미래예측이 필요하다
- 최소 최근 사용 (LRU, least recently used) 방식
  - MIN알고리즘에 근접할 정도의 최고 적중률을 보임
  - 모든 블록에 대해 최근에 참조된 정보를 포함해야하므로 구현 비용이 높음
- 무작위 (random) 방식
  - 임의의 캐시블록을 선택해서 추출함으로써 캐시 메모리 공간을 준비
  - 효율성은 보장하기 어렵지만, 구현 비용이 저렴하고 간단
- 선입선출 (FIFO) 방식
  - 캐시 메모리에 먼저 적재된 블록을 먼저 추출함으로써 캐시 메모리 공간을 준비
  - 효율성을 보장하기 어렵지만 time locality 기반으로 구현 비용이 저렴

### 🟣 블록갱신 방식

캐시가 존재하는 컴퓨터라면 데이터는 메모리와 캐시 두 곳에 동시에 존재할 수 있다. 같은 데이터라면 어느 곳에 있든, 같은 정보를 가지고 있어야 한다. 하지만 캐시를 사용하게 되면, 동일블록(같은 주소)에 다른 값을 갖는 현상이 발생한다.

주로 데이터 캐시에만 write하고 메인 메모리에는 쓰지 않는 경우가 발생한다. (캐시 시스템에서는 캐시메모리에 있는 데이터에 Read, write 하는 것을 우선적으로 수행되기 때문에!!)

블록 갱신 방식은 캐시의 내용을 메모리와 일치시키는 시점에 따라 두가지로 나뉜다.

```
<즉시쓰기>
- write 연산시 항상 데이터를 메모리와 캐시에 같이 쓰는 방법
- 성능저하가 심함
- 메모리까지 가는게 오래걸려서, 캐시메모리를 갖다놨더니, 자꾸 메모리에 방문하는 꼴
- write buffer를 통해서 완화시키기는 하지만, 이마저도 큰 buffer가 필요
```

- Write buffer
  - write buffer란, 버퍼에서 컴퓨터의 RAM 영역으로 기록 될 수 있어야하는 정보를 보유한다.

```
<나중쓰기>
- 쓰기 발생 시 새로운 값은 캐시 내 블록에만 쓰고, 나중에 캐시에서 나가는 블록이 쓰기 연산에 의해 수행됐을 경우, 다음 하위 레벨의 메모리에 데이터 갱신
- 속도가 빠르고 메모리 트래픽이 감소한다.
- 직접쓰기방식보다 구현과 설계가 어렵다.
```



### 🟣 상황에 따른 캐시 메모리 성능 향상 방법

위에서 말했듯이, 성능을 향상시키기 위해서는 실패율을 낮춰야한다. 캐시 실패 유형은 다음과 같다.

- Cold Miss: 해당 메모리 주소를 처음 불러서 나는 미스
- Capacity Miss(용량 실패): 캐시 메모리의 공간이 부족해서 나는 미스. (Conflict 는 주소 할당 문제, Capacity는 공간 문제라고 볼 수 있음)
- Conflict Miss(충돌실패): 캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 메모리 주소에 할당되어 있어서 나는 미스 (direct mapped cache 에서 많이 발생한다. 완전연관사상에서는 발생하지 않는다.)
- Compulsory Miss (강제실패): 해당 메모리 블록의 최초 접근에 의한 캐시미스

위에서 말했듯, 캐시의 성능 평가 기준은 ```적중률```, 그리고 ```latancy```로 판단한다.

상황별로 캐시의 성능을 향상시키려면 아래와 같이 해보자.

1. 실패율을 줄이자
   - 강제실패를 감소시키려면 : 블록을 크게, 또는 효과적인 prefetching을 진행
   - 충돌실패를 감소시키려면 : 연관도를 높이자.
   - 용량실패를 감소시키려면 : 캐시 용량을 크게하자.
   - 컴파일러를 통한 프로그램의 메모리 사용 최적화를 통해 

2. 실패 패널티를 줄이자 : 메모리 엑세스 타임을 줄이자.
   - 메모리 대역폭 향상
   - 블록 크기 줄이기
3. 적중시간을 줄이자
   - 캐시 엑세스 시간을 줄여야함
   - 캐시의 소용량화
   - 직접사상방식 채택 

<br>

### 📖 Reference

[캐시 개념 출처](https://velog.io/@wanzekim/cs-cache)

[캐시메모리 이미지와 참조지역성 출처](https://mangchhe.github.io/cs/2021/12/27/CacheMemory/)

[캐시메모리 성능과 지역성이 원리 출처](https://velog.io/@klloo/os-memory-cache)

[대략적인 캐시 메모리에 관한 본문 출처](https://aldrn29.tistory.com/m/66)

[캐시에 필요한 전략과 설계 논점](https://kimtaehyun98.tistory.com/48)

[직접사상](https://jhnyang.tistory.com/114)

